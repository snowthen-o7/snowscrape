# "org" ensures this Service is used with the correct Serverless Framework Access Key.
org: snowscrape
# "app" enables Serverless Framework Dashboard features and sharing them with other Services.
app: snowscrape-backend
# "service" is the name of this project. This will also be added to your AWS resource names.
service: snowscrape

provider:
  name: aws
  runtime: python3.12
  region: us-east-2
  stage: ${opt:stage, 'dev'} # Default to 'dev' if no stage is specified
  environment:
    CLERK_JWT_PUBLIC_KEY: ${self:custom.clerkJwtPublicKey.${self:provider.stage}}  # Conditional key based on the stage
    CLERK_JWT_SECRET_KEY: ${self:custom.clerkJwtSecretKey.${self:provider.stage}}  # Conditional key based on the stage
    DYNAMODB_JOBS_TABLE: ${self:custom.dynamoDbJobsTable}
    DYNAMODB_URLS_TABLE: ${self:custom.dynamoDbUrlsTable}
    REGION: ${self:provider.region}
    S3_BUCKET: ${self:custom.s3Bucket}
    SQS_JOB_QUEUE: ${self:custom.sqsJobQueue}
    SQS_JOB_QUEUE_URL: ${self:custom.sqsJobQueueUrl}
  iamRoleStatements:
    - Effect: "Allow"
      Action:
        - "dynamodb:*"
      Resource:
        - "arn:aws:dynamodb:${self:provider.region}:*:table/${self:custom.dynamoDbJobsTable}"
     
    - Effect: "Allow"
      Action:
        - "s3:*"
      Resource:
        - "arn:aws:s3:::${self:custom.s3Bucket}/*"

    - Effect: "Allow"
      Action:
        - "sqs:*"
      Resource:
        - "arn:aws:sqs:${self:provider.region}:*:${self:custom.sqsJobQueue}"

functions:
  createJob:
    name: snowscrape-create-job
    handler: handler.create_job_handler
    events:
      - http:
          path: jobs
          method: post
          cors: true

  deleteJob:
    name: snowscrape-delete-job
    handler: handler.delete_job_handler
    events:
      - http:
          path: jobs/{job_id}
          method: delete
          cors: true

  getAllJobStatuses:
    name: snowscrape-get-all-job-statuses
    handler: handler.get_all_job_statuses_handler
    events:
      - http:
          path: jobs/status
          method: get
          cors: true

  getCrawlDetails:
    name: snowscrape-get-crawl-details
    handler: handler.get_crawl_handler
    events:
      - http:
          path: jobs/{job_id}/crawls/{crawl_id}
          method: get
          cors: true

  getJobCrawlStatus:
    name: snowscrape-get-job-crawls
    handler: handler.get_job_crawls_handler
    events:
      - http:
          path: jobs/{job_id}/crawls
          method: get
          cors: true

  getJobDetails:
    name: snowscrape-get-job-details
    handler: handler.get_job_details_handler
    events:
      - http:
          path: jobs/{job_id}
          method: get
          cors: true

  pauseJob:
    name: snowscrape-pause-job
    handler: handler.pause_job_handler
    events:
      - http:
          path: jobs/{job_id}/pause
          method: patch
          cors: true

  # Job processing function (Triggered by SQS)
  processJob:
    name: snowscrape-process-job
    handler: handler.process_job_handler
    events:
      - sqs:
          arn:
            Fn::GetAtt:
              - JobQueue
              - Arn
          batchSize: 5  # Controls how many messages are processed at once

  refreshJob:
    name: snowscrape-refresh-job
    handler: handler.refresh_job_handler
    events:
      - http:
          path: jobs/{job_id}/refresh
          method: post
          cors: true

  resumeJob:
    name: snowscrape-resume-job
    handler: handler.resume_job_handler
    events:
      - http:
          path: jobs/{job_id}/resume
          method: patch
          cors: true

  scheduleJobs:
    handler: handler.schedule_jobs_handler
    events:
      - schedule:
          name: "RunJobsEveryHour" # You can use rate expressions or cron jobs
          rate: rate(1 hour) # Runs every hour

  updateJob:
    name: snowscrape-update-job
    handler: handler.update_job_handler
    events:
      - http:
          path: jobs/{job_id}
          method: put
          cors: true

  validateSftpUrl:
    handler: handler.validate_sftp_url_handler
    events:
      - http:
          path: validate-sftp-url
          method: post
          cors: true

resources:
  Resources:
    JobsDynamoDbTable:
      Type: "AWS::DynamoDB::Table"
      Properties:
        TableName: ${self:custom.dynamoDbJobsTable}
        AttributeDefinitions:
          - AttributeName: job_id  # Define the primary key attribute
            AttributeType: S       # S stands for String type
          - AttributeName: status  # (Optional) GSI to query jobs by status
            AttributeType: S
        KeySchema:
          - AttributeName: job_id
            KeyType: HASH          # The primary key (hash key)
        GlobalSecondaryIndexes:    # (Optional) GSI to query by status
          - IndexName: StatusIndex
            KeySchema:
              - AttributeName: status
                KeyType: HASH
            Projection:
              ProjectionType: ALL
        BillingMode: PAY_PER_REQUEST

    UrlsDynamoDbTable:
      Type: "AWS::DynamoDB::Table"
      Properties:
        TableName: ${self:custom.dynamoDbUrlsTable}  # A single table for all URLs across jobs
        AttributeDefinitions:
          - AttributeName: job_id  # Partition Key
            AttributeType: S       # String
          - AttributeName: url  # Sort Key
            AttributeType: S       # String
          - AttributeName: status  # Attribute for the GSI
            AttributeType: S       # String
        KeySchema:
          - AttributeName: job_id  # Partition Key for URLs by job
            KeyType: HASH
          - AttributeName: url  # Sort Key for URL under each job
            KeyType: RANGE
        BillingMode: PAY_PER_REQUEST
        GlobalSecondaryIndexes:
          - IndexName: StatusIndex  # Optional index to query URLs by status
            KeySchema:
              - AttributeName: status
                KeyType: HASH
            Projection:
              ProjectionType: ALL

    # SQS Queue for job processing
    JobQueue:
      Type: "AWS::SQS::Queue"
      Properties:
        QueueName: ${self:custom.sqsJobQueue}

    SnowscrapeResultsBucket:
      Type: "AWS::S3::Bucket"
      Properties:
        BucketName: ${self:custom.s3Bucket}

plugins:
  - serverless-python-requirements

custom:
  pythonRequirements:
    dockerizePip: true  # Ensures proper packaging of dependencies in a Docker container
  dynamoDbJobsTable: SnowscrapeJobs
  dynamoDbUrlsTable: SnowscrapeUrls
  s3Bucket: snowscrape-results
  sqsJobQueue: SnowscrapeJobQueue
  sqsJobQueueUrl: https://sqs.us-east-2.amazonaws.com/390844772519/SnowscrapeJobQueue
  clerkJwtPublicKey:
    dev: |
      -----BEGIN PUBLIC KEY-----
      MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAoZVvkucSn5kVAbJNzz0O
      9ylvrQA6svwe3K4WitLygsQIqbyjz5hUVAMj668n8xft/JTKkxOCorbpj0Y90lN+
      Z6Ge7k9gqMgTOJw8WE6w/j5RcTzLw3Fd81OU3T6D2SF6/51uNsvP3F4KieAJoImH
      Vg2fUHjNFuRwh7TyB5X5f1q3nk6uVqSUOGbf6P0uvoYXI9n8EppTgn5/LbV0K9kF
      jo2x0vyRmSun/klUoNCuBAPAbrG0bqwADvzvhPsHdXz61jxnBaLO+yD3kXEBzety
      7XTZhm8r8oaAmfup+3aIt7BCiAXRWQ5UfPNZ+tv+93HOqsOJfI96q6z9vgF+7QOr
      xQIDAQAB
      -----END PUBLIC KEY-----
    prod: "your-clerk-public-key-for-prod"
  clerkJwtSecretKey:
    dev: |
      sk_test_xFXzGKYU7lhtFBel98iewFsgkNwwyCgWAARdRaU5dA
    prod: "your-clerk-secret-key-for-prod"