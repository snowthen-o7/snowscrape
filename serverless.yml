# "org" ensures this Service is used with the correct Serverless Framework Access Key.
org: snowscrape
# "app" enables Serverless Framework Dashboard features and sharing them with other Services.
app: snowscrape-backend
# "service" is the name of this project. This will also be added to your AWS resource names.
service: snowscrape

provider:
  name: aws
  runtime: python3.12
  region: us-east-2
  environment:
    DYNAMODB_TABLE: ${self:custom.dynamoDbTable}
    REGION: ${self:provider.region}
    S3_BUCKET: ${self:custom.s3Bucket}
  iamRoleStatements:
    - Effect: "Allow"
      Action:
        - "dynamodb:Scan"  # Allows scanning the DynamoDB table
        - "dynamodb:Query"
        - "dynamodb:UpdateItem"
        - "dynamodb:PutItem"
        - "dynamodb:GetItem"
      Resource:
        - "arn:aws:dynamodb:${self:provider.region}:*:table/${self:custom.dynamoDbTable}"
     
    - Effect: "Allow"
      Action:
        - "s3:*"
      Resource:
        - "arn:aws:s3:::${self:custom.s3Bucket}/*"

functions:
  createJob:
    name: snowscrape-create-job
    handler: handler.create_job
    events:
      - http:
          path: jobs
          method: post
          cors: true

  deleteJob:
    name: snowscrape-delete-job
    handler: handler.delete_job
    events:
      - http:
          path: jobs/{job_id}
          method: delete
          cors: true

  getAllJobStatuses:
    name: snowscrape-get-all-job-statuses
    handler: handler.get_all_job_statuses
    events:
      - http:
          path: jobs/status
          method: get
          cors: true

  getCrawlDetails:
    name: snowscrape-get-crawl-details
    handler: handler.get_crawl
    events:
      - http:
          path: jobs/{job_id}/crawls/{crawl_id}
          method: get
          cors: true

  getJobCrawlStatus:
    name: snowscrape-get-job-crawls
    handler: handler.get_job_crawls
    events:
      - http:
          path: jobs/{job_id}/crawls
          method: get
          cors: true

  getJobDetails:
    name: snowscrape-get-job-details
    handler: handler.get_job_details
    events:
      - http:
          path: jobs/{job_id}
          method: get
          cors: true

  pauseJob:
    name: snowscrape-pause-job
    handler: handler.pause_job
    events:
      - http:
          path: jobs/{job_id}/pause
          method: patch
          cors: true

  refreshJob:
    name: snowscrape-refresh-job
    handler: handler.refresh_job
    events:
      - http:
          path: jobs/{job_id}/refresh
          method: post
          cors: true

  resumeJob:
    name: snowscrape-resume-job
    handler: handler.resume_job
    events:
      - http:
          path: jobs/{job_id}/resume
          method: patch
          cors: true

  updateJob:
    name: snowscrape-update-job
    handler: handler.update_job
    events:
      - http:
          path: jobs/{job_id}
          method: put
          cors: true

resources:
  Resources:
    JobsDynamoDbTable:
      Type: "AWS::DynamoDB::Table"
      Properties:
        TableName: ${self:custom.dynamoDbTable}
        AttributeDefinitions:
          - AttributeName: job_id  # Define the primary key attribute
            AttributeType: S       # S stands for String type
          - AttributeName: status  # (Optional) GSI to query jobs by status
            AttributeType: S
        KeySchema:
          - AttributeName: job_id
            KeyType: HASH          # The primary key (hash key)
        GlobalSecondaryIndexes:    # (Optional) GSI to query by status
          - IndexName: StatusIndex
            KeySchema:
              - AttributeName: status
                KeyType: HASH
            Projection:
              ProjectionType: ALL
        BillingMode: PAY_PER_REQUEST
    SnowscrapeResultsBucket:
      Type: "AWS::S3::Bucket"
      Properties:
        BucketName: ${self:custom.s3Bucket}

plugins:
  - serverless-python-requirements

custom:
  pythonRequirements:
    dockerizePip: true  # Ensures proper packaging of dependencies in a Docker container
  dynamoDbTable: SnowscrapeJobs
  s3Bucket: snowscrape-results